{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing Decorater Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"행렬 연산 {func.__name__} 실행 시간: {end_time - start_time:.4f}초\")\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Head Attention (Scaled Dot Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfAttention(nn.Module):\n",
    "    # 데코레이터 사용해서 행렬 계산 시간 측정.\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, attention_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # embedding dim 입력을 받아서, attention dim 으로 변환\n",
    "        self.embed_size = embed_dim\n",
    "        self.attention_dim = attention_dim\n",
    "\n",
    "        # Q, K, V 행렬 변환 레이어.\n",
    "        self.W_q = nn.Linear(embed_dim, attention_dim)\n",
    "        self.W_k = nn.Linear(embed_dim, attention_dim)\n",
    "        self.W_v = nn.Linear(embed_dim, attention_dim)\n",
    "\n",
    "        # 출력 프로젝션 (원래 차원으로 복원)\n",
    "        self.out_proj = nn.Linear(attention_dim, embed_dim)\n",
    "\n",
    "        # 드롭아웃 추가 (정규화 효과)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    @timing_decorator\n",
    "    def forward(self, x, mask=None):\n",
    "        # Q, K, V 행렬 계산\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        # Q, K 행렬의 내적 계산 <- arguument (-2, -1) 은 tensor의 뒤 두 차원을 뒤집어서 계산 / batch 고려\n",
    "        attention_score = Q @ K.transpose(-2, -1)\n",
    "        # 내적 결과를 정규화\n",
    "        attention_score = attention_score / math.sqrt(self.attention_dim)\n",
    "        # 마스킹 지원 \n",
    "        if mask is not None:\n",
    "            attention_score = attention_score.masked_fill(mask == 0, -1e9)\n",
    "        # 정규화된 내적 결과에 대한 소프트맥스 함수 적용, 행 적용.\n",
    "        attention_score = self.dropout(F.softmax(attention_score, dim=-1))\n",
    "\n",
    "        # 소프트맥스 결과와 V 행렬의 곱 계산\n",
    "        attention_score = attention_score @ V\n",
    "        # 원래 차원으로 복원\n",
    "        output = self.out_proj(attention_score)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.0350초\n",
      "행렬 연산 forward 실행 시간: 0.6955초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10000, 10000])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = selfAttention(embed_dim=10000, attention_dim=100)\n",
    "model(torch.randn(1, 10000, 10000)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# claude 3.7 최적화 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfAttention(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, attention_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # embedding dim 입력을 받아서, attention dim 으로 변환\n",
    "        self.embed_size = embed_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.scale = math.sqrt(attention_dim)\n",
    "        \n",
    "        # 1. 행렬 연산 통합 - 하나의 선형 레이어로 Q, K, V 동시 계산\n",
    "        # 기존에는 Q, K, V를 각각 접근하여 계산해, 메모리 접근이 비효율적. -> 하나의 선형 레이어로 계산\n",
    "        # 큰 레이어로 계산하고 나누는 형식으로 사용.\n",
    "        self.qkv_proj = nn.Linear(embed_dim, 3 * attention_dim)\n",
    "        \n",
    "        # 2. 출력 프로젝션 추가 (원래 차원으로 복원)\n",
    "        self.out_proj = nn.Linear(attention_dim, embed_dim)\n",
    "        \n",
    "        # 3. 드롭아웃 추가 (정규화 효과)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    @timing_decorator\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # 4. 통합된 QKV 계산 및 분리(chunk)\n",
    "        qkv = self.qkv_proj(x).chunk(3, dim=-1)\n",
    "        Q, K, V = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        # 5. 행렬 곱셈 최적화 (@ 연산자 사용)\n",
    "        attention_score = (Q @ K.transpose(-2, -1)) / self.scale\n",
    "        \n",
    "        # 6. 마스킹 지원 추가\n",
    "        if mask is not None:\n",
    "            attention_score = attention_score.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # 7. 소프트맥스 및 드롭아웃\n",
    "        attention_weights = self.dropout(F.softmax(attention_score, dim=-1))\n",
    "        \n",
    "        # 8. 가중치 적용 및 출력 프로젝션\n",
    "        output = attention_weights @ V\n",
    "        output = self.out_proj(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.0198초\n",
      "행렬 연산 forward 실행 시간: 0.5833초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10000, 10000])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = selfAttention(embed_dim=10000, attention_dim=100)\n",
    "model(torch.randn(1, 10000, 10000), mask=None).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, head_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.attention_dim = embed_dim // head_num\n",
    "        self.head_num = head_num\n",
    "        \n",
    "        self.heads = nn.ModuleList([selfAttention(self.embed_dim, self.attention_dim) for _ in range(head_num)])\n",
    "\n",
    "    @timing_decorator\n",
    "    def forward(self, x, mask=None):\n",
    "        return torch.cat([head(x, mask) for head in self.heads], dim=-1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.3044초\n",
      "행렬 연산 __init__ 실행 시간: 0.2930초\n",
      "행렬 연산 __init__ 실행 시간: 0.2900초\n",
      "행렬 연산 __init__ 실행 시간: 0.2926초\n",
      "행렬 연산 forward 실행 시간: 2.5743초\n",
      "행렬 연산 forward 실행 시간: 2.7165초\n",
      "행렬 연산 forward 실행 시간: 2.7462초\n",
      "행렬 연산 forward 실행 시간: 3.2253초\n",
      "행렬 연산 forward 실행 시간: 11.9727초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0217, -0.0096,  0.0127,  ...,  0.0042, -0.0054,  0.0151],\n",
       "         [-0.0197, -0.0103,  0.0152,  ...,  0.0014, -0.0107,  0.0209],\n",
       "         [-0.0182, -0.0118,  0.0141,  ..., -0.0017, -0.0094,  0.0192],\n",
       "         ...,\n",
       "         [-0.0201, -0.0081,  0.0132,  ..., -0.0009, -0.0114,  0.0178],\n",
       "         [-0.0231, -0.0096,  0.0137,  ...,  0.0001, -0.0103,  0.0178],\n",
       "         [-0.0188, -0.0105,  0.0091,  ...,  0.0005, -0.0121,  0.0194]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = multiHeadAttention(embed_dim=10000, head_num=4)\n",
    "model(torch.randn(1, 10000, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiHeadAttention(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, head_num, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.head_dim = embed_dim // head_num\n",
    "        self.head_num = head_num\n",
    "        \n",
    "        # 1. 개별 selfAttention 모듈 대신 통합 프로젝션 사용\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        # 2. 출력 프로젝션 추가\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        # 3. 드롭아웃 추가\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # 4. 스케일링 팩터 미리 계산\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "    \n",
    "    @timing_decorator\n",
    "    def forward(self, x, memory=None, mask=None):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # 5. 인코더-디코더 어텐션 지원\n",
    "        # memory가 None이면 self-attention, 아니면 encoder-decoder attention\n",
    "        if memory is None:\n",
    "            # Self-Attention 모드\n",
    "            memory = x\n",
    "        \n",
    "        # memory의 시퀀스 길이 가져오기\n",
    "        _, mem_seq_len, _ = memory.shape\n",
    "        \n",
    "        # 6. 쿼리는 디코더 입력(x)에서, 키와 값은 인코더 출력(memory)에서 가져옴\n",
    "        q = self.q_proj(x).view(batch_size, seq_len, self.head_num, self.head_dim)\n",
    "        k = self.k_proj(memory).view(batch_size, mem_seq_len, self.head_num, self.head_dim)\n",
    "        v = self.v_proj(memory).view(batch_size, mem_seq_len, self.head_num, self.head_dim)\n",
    "        \n",
    "        # 7. 차원 순서 변경으로 병렬 처리 최적화\n",
    "        q = q.transpose(1, 2)  # [batch_size, head_num, seq_len, head_dim]\n",
    "        k = k.transpose(1, 2)  # [batch_size, head_num, mem_seq_len, head_dim]\n",
    "        v = v.transpose(1, 2)  # [batch_size, head_num, mem_seq_len, head_dim]\n",
    "        \n",
    "        # 8. 병렬 어텐션 계산\n",
    "        # [batch_size, head_num, seq_len, mem_seq_len]\n",
    "        attention_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        # 9. 마스킹 지원 (인코더-디코더 어텐션용 마스크 처리)\n",
    "        if mask is not None:\n",
    "            # 마스크 형태에 따른 처리\n",
    "            if mask.dim() == 3:  # [batch_size, seq_len, mem_seq_len]\n",
    "                mask = mask.unsqueeze(1)  # [batch_size, 1, seq_len, mem_seq_len]\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # 10. 소프트맥스 및 드롭아웃\n",
    "        attention_weights = self.dropout(F.softmax(attention_scores, dim=-1))\n",
    "        \n",
    "        # 11. 가중치 적용 및 차원 재구성\n",
    "        # [batch_size, head_num, seq_len, head_dim]\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        \n",
    "        # 12. 헤드 결합\n",
    "        output = output.transpose(1, 2)  # [batch_size, seq_len, head_num, head_dim]\n",
    "        output = output.reshape(batch_size, seq_len, self.embed_dim)\n",
    "        \n",
    "        # 13. 출력 프로젝션\n",
    "        output = self.out_proj(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 1.2372초\n",
      "행렬 연산 forward 실행 시간: 11.7844초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0070,  0.0037,  0.0028,  ..., -0.0101,  0.0180,  0.0028],\n",
       "         [-0.0075, -0.0023,  0.0051,  ..., -0.0098,  0.0193,  0.0026],\n",
       "         [-0.0081,  0.0019, -0.0010,  ..., -0.0102,  0.0172,  0.0018],\n",
       "         ...,\n",
       "         [-0.0073,  0.0012,  0.0008,  ..., -0.0111,  0.0146, -0.0021],\n",
       "         [-0.0103,  0.0013,  0.0017,  ..., -0.0128,  0.0145,  0.0039],\n",
       "         [-0.0027,  0.0015,  0.0013,  ..., -0.0099,  0.0165,  0.0019]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = multiHeadAttention(embed_dim=10000, head_num=4)\n",
    "model(torch.randn(1, 10000, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.0061초\n",
      "행렬 연산 forward 실행 시간: 0.0023초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0949,  0.1345,  0.0263,  ..., -0.0280, -0.0293, -0.0613],\n",
       "        [-0.0613, -0.0645,  0.1776,  ..., -0.3037, -0.2003, -0.0486],\n",
       "        [ 0.3811,  0.3652,  0.1756,  ..., -0.2144,  0.1886, -0.0051],\n",
       "        ...,\n",
       "        [-0.1124,  0.0013, -0.2961,  ..., -0.1068, -0.1443, -0.0386],\n",
       "        [-0.1595,  0.3505,  0.0045,  ..., -0.4028, -0.1005, -0.6073],\n",
       "        [-0.2140,  0.0560,  0.1108,  ..., -0.0988, -0.3059, -0.3197]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc2 = nn.Linear(embed_dim, embed_dim)\n",
    "    @timing_decorator\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "model = FeedForward(embed_dim=100)\n",
    "model(torch.randn(100, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.0012초\n",
      "행렬 연산 forward 실행 시간: 0.0011초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9015, -0.8391,  1.3860,  ...,  1.7770,  1.1994, -0.8444],\n",
       "        [-0.1553, -1.3756,  1.6660,  ...,  1.5024,  0.5604,  0.6539],\n",
       "        [ 0.9111,  0.3385,  0.0722,  ..., -0.1994, -2.1402,  0.9485],\n",
       "        ...,\n",
       "        [-0.1498, -0.1131,  0.8218,  ..., -0.7722,  0.3327, -1.3569],\n",
       "        [-0.6441,  0.4015,  0.8817,  ...,  0.2852,  0.1499, -0.5180],\n",
       "        [ 1.6629, -0.4979, -0.5406,  ...,  1.0214,  0.3287, -0.1590]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, ff_dim=None, dropout_rate=0.1, activation='gelu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 유연한 차원 설정 (일반적으로 ff_dim은 embed_dim의 4배)\n",
    "        self.ff_dim = 4 * embed_dim if ff_dim is None else ff_dim\n",
    "        \n",
    "        # 2. 표준 Transformer 구조 적용\n",
    "        self.fc1 = nn.Linear(embed_dim, self.ff_dim)\n",
    "        self.fc2 = nn.Linear(self.ff_dim, embed_dim)\n",
    "        \n",
    "        # 3. 드롭아웃 추가\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # 4. 활성화 함수 선택 지원\n",
    "        if activation == 'relu':\n",
    "            self.activation = F.relu\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = F.gelu\n",
    "        elif activation == 'silu' or activation == 'swish':\n",
    "            self.activation = F.silu\n",
    "        else:\n",
    "            raise ValueError(f\"지원하지 않는 활성화 함수: {activation}\")\n",
    "        \n",
    "        # 5. 레이어 정규화 추가 (선택적)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # 6. 가중치 초기화\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        # Xavier/Glorot 초기화\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "    \n",
    "    @timing_decorator\n",
    "    def forward(self, x):\n",
    "        # 7. 잔차 연결(residual connection) 적용\n",
    "        residual = x\n",
    "        \n",
    "        # 8. 표준 피드포워드 네트워크 흐름\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 9. 잔차 연결 및 레이어 정규화\n",
    "        x = residual + x\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = FeedForward(embed_dim=100)\n",
    "model(torch.randn(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.pe = torch.zeros(max_len, embed_dim)\n",
    "        for pos in range(max_len):\n",
    "            for i in range(embed_dim):\n",
    "                if i % 2 == 0:\n",
    "                    self.pe[pos, i] = math.sin(pos / (10000 ** (i/embed_dim)))\n",
    "                else:\n",
    "                    self.pe[pos, i] = math.cos(pos / (10000 ** ((i-1)/embed_dim)))\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(1), :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 12.2531초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2092,  1.6836,  1.2086,  ...,  1.9223,  0.7860,  0.9179],\n",
       "        [ 0.5510,  0.6314,  1.1510,  ...,  0.7919,  2.3845,  1.1229],\n",
       "        [ 0.7000, -0.8367,  1.3397,  ...,  0.7099,  1.0221,  1.6009],\n",
       "        ...,\n",
       "        [-1.1488,  0.5710, -0.4910,  ...,  0.6921,  0.0192,  3.6388],\n",
       "        [-0.1267,  0.9919,  0.8790,  ...,  0.5224,  1.4226,  0.5621],\n",
       "        [-0.0551,  0.3650,  1.0389,  ...,  0.7748,  0.3693,  1.4311]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 1000\n",
    "model = PositionalEncoding(embed_dim=embed_dim)\n",
    "model(torch.randn(embed_dim, embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 2. 벡터화 연산으로 변경 (중첩 for문 제거)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        \n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # 3. 등록된 버퍼로 변환 (모델 저장 시 함께 저장됨)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "        # 4. 임베딩 차원 저장 (디버깅 및 문서화 목적)\n",
    "        self.embed_dim = embed_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 5. 입력 시퀀스 길이에 맞게 위치 인코딩 잘라서 사용\n",
    "        # x 형태: (batch_size, seq_len, embed_dim)\n",
    "        return x + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.0083초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5656,  1.2081,  0.7978,  ...,  0.6967,  1.6393, -0.6661],\n",
       "         [ 1.4990, -0.7042,  1.1031,  ..., -0.1064, -0.4657,  0.9256],\n",
       "         [ 1.5408,  0.0763,  0.7209,  ...,  1.8202,  1.1380,  1.8009],\n",
       "         ...,\n",
       "         [-1.1181,  0.2585, -0.3091,  ..., -1.1144, -0.6131, -0.1160],\n",
       "         [-2.6969,  1.8758, -0.0774,  ...,  0.4491,  0.7902,  0.9058],\n",
       "         [-0.4565,  2.2082,  0.9516,  ..., -0.4351,  0.8622,  0.0206]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 1000\n",
    "model = PositionalEncoding(embed_dim=embed_dim)\n",
    "model(torch.randn(embed_dim, embed_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add & Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, head_num, ff_dim=None, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = multiHeadAttention(embed_dim, head_num, dropout_rate)\n",
    "        self.ffn = FeedForward(embed_dim, ff_dim, dropout_rate)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    @timing_decorator\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.norm1(x + self.self_attn(x, mask))\n",
    "        x = self.norm2(x + self.ffn(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.0008초\n",
      "행렬 연산 __init__ 실행 시간: 0.0007초\n",
      "행렬 연산 __init__ 실행 시간: 0.0016초\n",
      "행렬 연산 forward 실행 시간: 0.0009초\n",
      "행렬 연산 forward 실행 시간: 0.0007초\n",
      "행렬 연산 forward 실행 시간: 0.0018초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1076,  0.9659, -2.2989,  ...,  0.9238,  0.9898, -1.1221],\n",
       "         [-1.3739,  0.8757, -0.0176,  ..., -0.7255, -2.1582, -1.6540],\n",
       "         [ 0.5585,  0.8772, -0.4673,  ..., -1.0803,  0.6039, -0.8235],\n",
       "         ...,\n",
       "         [-0.5640,  1.8456,  0.6362,  ..., -0.2410,  0.5605,  0.2439],\n",
       "         [-0.1371,  1.7360, -1.7944,  ..., -0.8012,  1.3335, -1.3292],\n",
       "         [ 0.6319, -0.5479, -0.6247,  ..., -0.8504, -0.2272, -0.9490]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EncoderLayer(embed_dim=100, head_num=4)\n",
    "model(torch.randn(1, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, head_num, ff_dim=None, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = multiHeadAttention(embed_dim, head_num, dropout_rate)\n",
    "        self.cross_attn = multiHeadAttention(embed_dim, head_num, dropout_rate)\n",
    "        self.ffn = FeedForward(embed_dim, ff_dim, dropout_rate)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    @timing_decorator\n",
    "    def forward(self, x, memory, mask=None):\n",
    "        x = self.norm1(x + self.self_attn(x, mask))\n",
    "        x = self.norm2(x + self.cross_attn(x, memory, mask))\n",
    "        x = self.norm3(x + self.ffn(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 0.0009초\n",
      "행렬 연산 __init__ 실행 시간: 0.0005초\n",
      "행렬 연산 __init__ 실행 시간: 0.0006초\n",
      "행렬 연산 __init__ 실행 시간: 0.0024초\n",
      "행렬 연산 forward 실행 시간: 0.0008초\n",
      "행렬 연산 forward 실행 시간: 0.0008초\n",
      "행렬 연산 forward 실행 시간: 0.0007초\n",
      "행렬 연산 forward 실행 시간: 0.0028초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1695,  0.5823,  0.6928,  ..., -1.6887, -1.8353, -0.3903],\n",
       "         [ 0.7396, -0.2839,  0.7600,  ..., -0.3781,  0.1145, -1.4993],\n",
       "         [-0.0114,  0.6360,  1.4768,  ..., -0.3988, -1.0712,  1.6964],\n",
       "         ...,\n",
       "         [ 0.7200,  0.2242,  1.1404,  ..., -0.0574,  1.0430,  0.4501],\n",
       "         [-1.6600, -0.7676, -0.8377,  ...,  0.0948, -1.8584, -0.8328],\n",
       "         [ 0.4964,  1.1080,  0.4698,  ..., -1.6858,  1.0066, -0.3532]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecoderLayer(embed_dim=100, head_num=4)\n",
    "model(x = torch.randn(1, 100, 100), memory = torch.randn(1, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    @timing_decorator\n",
    "    def __init__(self, embed_dim, head_num, ff_dim=None, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderLayer(embed_dim, head_num, ff_dim, dropout_rate)\n",
    "        self.decoder = DecoderLayer(embed_dim, head_num, ff_dim, dropout_rate)\n",
    "        self.linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    @timing_decorator\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        src = self.encoder(src, src_mask)\n",
    "        tgt = self.decoder(tgt, src, tgt_mask)        \n",
    "        return self.linear(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 연산 __init__ 실행 시간: 1.1658초\n",
      "행렬 연산 __init__ 실행 시간: 4.3232초\n",
      "행렬 연산 __init__ 실행 시간: 5.4894초\n",
      "행렬 연산 __init__ 실행 시간: 1.1191초\n",
      "행렬 연산 __init__ 실행 시간: 1.1293초\n",
      "행렬 연산 __init__ 실행 시간: 4.5027초\n",
      "행렬 연산 __init__ 실행 시간: 6.7520초\n",
      "행렬 연산 __init__ 실행 시간: 12.5215초\n",
      "행렬 연산 forward 실행 시간: 0.1201초\n",
      "행렬 연산 forward 실행 시간: 0.2046초\n",
      "행렬 연산 forward 실행 시간: 0.3272초\n",
      "행렬 연산 forward 실행 시간: 0.1172초\n",
      "행렬 연산 forward 실행 시간: 0.1161초\n",
      "행렬 연산 forward 실행 시간: 0.2542초\n",
      "행렬 연산 forward 실행 시간: 0.4906초\n",
      "행렬 연산 forward 실행 시간: 0.8446초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4427, -1.5164,  0.2352,  ...,  0.6473,  0.7047, -0.4855],\n",
       "         [ 0.1503, -1.1656,  1.5674,  ..., -1.0098,  0.2365, -0.1964],\n",
       "         [-0.8602,  0.2901,  0.6377,  ...,  0.0171,  0.6700,  0.9817],\n",
       "         ...,\n",
       "         [-0.5442, -0.5437,  0.2300,  ..., -0.0323,  0.4300, -0.2441],\n",
       "         [ 0.1137,  0.2401, -0.7411,  ..., -0.4218,  0.5344,  1.0317],\n",
       "         [-0.3432,  1.3753, -0.5390,  ..., -1.5395,  0.4840, -0.4992]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 10000\n",
    "head_num = 8\n",
    "model = Transformer(embed_dim=embed_dim, head_num=head_num)\n",
    "model(torch.randn(1, 100, embed_dim), torch.randn(1, 100, embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
